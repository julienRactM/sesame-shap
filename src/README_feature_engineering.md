# Pipeline de Feature Engineering COMPAS

Ce module fournit un pipeline complet de pr√©processing pour le dataset COMPAS avec une approche consciente des biais.

## Fonctionnalit√©s Principales

### üîß Preprocessing Robuste
- **Traitement des valeurs manquantes** : Strat√©gies adapt√©es par type de variable
- **Encodage des variables cat√©gorielles** : One-hot encoding et label encoding
- **Cr√©ation de features d√©riv√©es** : Groupes d'√¢ge, cat√©gories d'ant√©c√©dents, interactions
- **Normalisation** : StandardScaler pour les features num√©riques

### üéØ Conscience des Biais
- **S√©paration des attributs sensibles** : race, sexe, √¢ge
- **Versions multiples du dataset** :
  - Complet (toutes les features)
  - Sans attributs sensibles (pour mitigation des biais)
  - Simplifi√© (pour interpr√©tabilit√©)
- **Documentation des sources de biais potentielles**

### üìä Contr√¥le Qualit√©
- **Validation des donn√©es** : D√©tection d'outliers, valeurs manquantes, doublons
- **Rapports d√©taill√©s** : M√©tadonn√©es compl√®tes, logs de processing
- **Tests de coh√©rence** : V√©rifications sp√©cifiques au dataset COMPAS

## Utilisation

### Utilisation Basique

```python
from src.feature_engineering import COMPASFeatureEngineer

# Initialiser le preprocesseur
processor = COMPASFeatureEngineer(random_state=42)

# Ex√©cuter le pipeline complet
results = processor.preprocess_compas_data('path/to/compas_data.csv')

# Sauvegarder les datasets trait√©s
processor.save_processed_datasets(
    results['datasets'], 
    'data/processed/'
)
```

### Pipeline D√©taill√©

```python
# 1. Chargement des donn√©es
df = processor.load_compas_data('data.csv')

# 2. Traitement des valeurs manquantes
df_clean = processor.handle_missing_values(df)

# 3. Encodage des variables cat√©gorielles
df_encoded, encoders = processor.encode_categorical_features(df_clean)

# 4. Cr√©ation des features d√©riv√©es
df_features = processor.create_derived_features(df_encoded)

# 5. Validation de la qualit√©
quality_report = processor.validate_data_quality(df_features)

# 6. Pr√©paration pour la mod√©lisation
datasets = processor.prepare_features_for_modeling(df_features)
```

## Features Cr√©√©es

### Features de Base (Encod√©es)
- **race_*** : Variables dummy pour les origines ethniques
- **sex_*** : Variables dummy pour le sexe
- **c_charge_degree_*** : Variables dummy pour le degr√© d'accusation
- **age_cat_encoded** : Cat√©gorie d'√¢ge encod√©e
- **score_text_encoded** : Score de risque textuel encod√©
- **risk_score_ordinal** : Score de risque ordinal (0-2)

### Features D√©riv√©es
- **age_group_detailed** : Groupes d'√¢ge d√©taill√©s (18-24, 25-34, etc.)
- **age_group_numeric** : Version num√©rique des groupes d'√¢ge
- **priors_category** : Cat√©gories d'ant√©c√©dents (None, Low, Medium, High, Very_High)
- **has_priors** : Indicateur binaire de pr√©sence d'ant√©c√©dents
- **many_priors** : Indicateur binaire de nombreux ant√©c√©dents (>3)
- **high_risk_score** : Indicateur binaire de score COMPAS √©lev√© (‚â•7)
- **medium_risk_score** : Indicateur binaire de score COMPAS moyen (4-6)
- **low_risk_score** : Indicateur binaire de score COMPAS faible (‚â§3)

### Features d'Interaction
- **age_priors_interaction** : Interaction √¢ge √ó nombre d'ant√©c√©dents
- **age_log** : Transformation logarithmique de l'√¢ge
- **priors_count_log** : Transformation logarithmique des ant√©c√©dents

### Features Temporelles
- **screening_delay_abs** : Valeur absolue du d√©lai d'√©valuation
- **screening_delay_category** : Cat√©gorie de d√©lai (Same_Day, Within_Week, etc.)

### Features Binaires
- **is_young** : Indicateur d'√¢ge < 25 ans
- **is_elderly** : Indicateur d'√¢ge > 65 ans

## Versions des Datasets

### 1. Dataset Complet (`full`)
- **35 features** incluant toutes les variables et features d√©riv√©es
- Recommand√© pour la mod√©lisation initiale et l'exploration

### 2. Dataset Sans Attributs Sensibles (`no_sensitive`)
- **23 features** sans race, sexe, et cat√©gories d'√¢ge directes
- Recommand√© pour l'analyse d'√©quit√© et la mitigation des biais

### 3. Dataset Simplifi√© (`simplified`)
- **8 features** principales s√©lectionn√©es pour l'interpr√©tabilit√©
- Recommand√© pour les mod√®les explicables et les pr√©sentations

## Rapport de Qualit√©

Le pipeline g√©n√®re automatiquement :

- **Analyse des valeurs manquantes** : Avant/apr√®s traitement
- **D√©tection d'outliers** : M√©thode IQR par variable
- **Distribution des variables** : Statistiques descriptives
- **Tests de coh√©rence** : V√©rifications sp√©cifiques COMPAS
- **Avertissements** : Signalement des probl√®mes potentiels

## Fichiers G√©n√©r√©s

### Datasets
- `compas_full_YYYYMMDD_HHMMSS.csv` : Dataset complet
- `compas_no_sensitive_YYYYMMDD_HHMMSS.csv` : Sans attributs sensibles
- `compas_simplified_YYYYMMDD_HHMMSS.csv` : Version simplifi√©e
- `*_train.csv` et `*_test.csv` : Splits d'entra√Ænement et de test

### M√©tadonn√©es
- `compas_metadata_YYYYMMDD_HHMMSS.json` : Informations compl√®tes
  - Description des datasets
  - Liste des features
  - Rapport de qualit√©
  - Log de processing
  - Description des features

## Recommandations d'Usage

### Pour l'Analyse d'√âquit√©
1. Utiliser le dataset **sans attributs sensibles**
2. Comparer les performances avec le dataset complet
3. Analyser l'importance des features potentiellement biais√©es

### Pour l'Interpr√©tabilit√©
1. Utiliser le dataset **simplifi√©**
2. Se concentrer sur les features principales
3. √âviter les interactions complexes

### Pour la Performance
1. Commencer avec le dataset **complet**
2. Utiliser la validation crois√©e stratifi√©e
3. Surveiller les m√©triques d'√©quit√©

## Exemple de R√©sultats

```
üìä 3 versions du dataset cr√©√©es:
  - full: 35 features, 1000 √©chantillons
  - no_sensitive: 23 features, 1000 √©chantillons  
  - simplified: 8 features, 1000 √©chantillons

üìã Impact de la suppression des attributs sensibles:
  - Performance avec attributs sensibles: 0.605
  - Performance sans attributs sensibles: 0.570
  - Diff√©rence: +0.035 (Impact mod√©r√© - √Ä investiguer)

‚úÖ Recommandations:
  - Le dataset simplifi√© offre des performances comparables
  - Le dataset sans attributs sensibles est disponible pour l'analyse d'√©quit√©
```

## Bonnes Pratiques

### Avant l'Utilisation
- V√©rifier la qualit√© des donn√©es sources
- Examiner le rapport de qualit√© g√©n√©r√©
- Comprendre les features cr√©√©es

### Pendant la Mod√©lisation
- Utiliser la validation crois√©e stratifi√©e
- Surveiller les m√©triques d'√©quit√©
- Comparer les performances entre versions

### Apr√®s la Mod√©lisation
- Analyser l'importance des features
- V√©rifier l'absence de biais dans les pr√©dictions
- Documenter les choix de preprocessing

## D√©pendances

- `pandas >= 1.5.0`
- `numpy >= 1.21.0`
- `scikit-learn >= 1.2.0`
- `matplotlib >= 3.6.0` (pour les visualisations)

## Contribution

Pour contribuer √† ce pipeline :

1. Respecter les conventions de nommage
2. Ajouter des tests pour les nouvelles fonctionnalit√©s
3. Documenter les nouvelles features cr√©√©es
4. Maintenir la compatibilit√© avec les versions existantes

## Support

Pour toute question ou probl√®me :

1. V√©rifier les logs de processing
2. Examiner le rapport de qualit√©
3. Consulter la documentation des features
4. V√©rifier les versions des d√©pendances