# SESAME-SHAP: Analyse d'InterprÃ©tabilitÃ© et de Biais COMPAS

## ğŸ¯ Vue d'Ensemble du Projet

**"SHAP is unlocking the secrets of complex models and revealing their true potential."**

Ce projet explore l'interprÃ©tabilitÃ© des modÃ¨les d'apprentissage automatique appliquÃ©s au dataset COMPAS (Correctional Offender Management Profiling for Alternative Sanctions) en utilisant SHAP (SHapley Additive exPlanations) et d'autres mÃ©thodes d'explication. L'objectif principal est de dÃ©tecter, analyser et mitiger les biais raciaux dans les prÃ©dictions de rÃ©cidive.

### ğŸ“‹ Contexte

Le systÃ¨me COMPAS est utilisÃ© dans le systÃ¨me judiciaire amÃ©ricain pour Ã©valuer le risque de rÃ©cidive des accusÃ©s. Une investigation de ProPublica en 2016 a rÃ©vÃ©lÃ© des biais raciaux significatifs dans ces prÃ©dictions, montrant que les dÃ©fendeurs African-American Ã©taient disproportionnellement classÃ©s comme Ã  haut risque par rapport aux dÃ©fendeurs Caucasian.

### ğŸ† Objectifs

1. **DÃ©tecter** les biais raciaux dans les prÃ©dictions COMPAS
2. **Analyser** l'interprÃ©tabilitÃ© avec SHAP, LIME et SAGE  
3. **Mitiger** les biais identifiÃ©s avec diverses stratÃ©gies
4. **Ã‰valuer** l'efficacitÃ© des techniques de mitigation
5. **Comparer** les mÃ©thodes d'interprÃ©tabilitÃ© (BONUS)

## ğŸš€ Installation et Configuration

### PrÃ©requis

- Python 3.8+
- pip ou conda
- Compte Kaggle (pour tÃ©lÃ©charger le dataset)

### Installation Rapide

```bash
# Cloner le repository
git clone <url-du-repo>
cd sesame-shap

# Lancer l'installation automatique
./install.sh
```

### Installation Manuelle

```bash
# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou venv\Scripts\activate  # Windows

# Installer les dÃ©pendances
pip install -r requirements.txt

# CrÃ©er la structure des dossiers
mkdir -p data/{raw,processed,models,results}
```

### Configuration Kaggle

Pour tÃ©lÃ©charger le dataset COMPAS:

1. CrÃ©er un compte sur [Kaggle](https://www.kaggle.com)
2. Obtenir votre API key depuis votre profil Kaggle
3. Configurer kagglehub selon la documentation

## ğŸ“ Structure du Projet

```
sesame-shap/
â”œâ”€â”€ src/                              # Modules Python principaux
â”‚   â”œâ”€â”€ data_acquisition.py          # TÃ©lÃ©chargement dataset COMPAS
â”‚   â”œâ”€â”€ exploratory_analysis.py      # Analyse exploratoire avec focus biais
â”‚   â”œâ”€â”€ feature_engineering.py       # Preprocessing et feature engineering
â”‚   â”œâ”€â”€ model_training.py            # EntraÃ®nement modÃ¨les ML
â”‚   â”œâ”€â”€ shap_analysis.py            # Analyse SHAP principal
â”‚   â”œâ”€â”€ bias_analysis.py            # DÃ©tection et mÃ©triques de biais
â”‚   â”œâ”€â”€ bias_mitigation.py          # StratÃ©gies de mitigation
â”‚   â”œâ”€â”€ fairness_evaluation.py      # Ã‰valuation efficacitÃ© mitigation
â”‚   â””â”€â”€ interpretability_comparison.py # Comparaison SHAP/LIME/SAGE
â”œâ”€â”€ data/                            # DonnÃ©es et rÃ©sultats
â”‚   â”œâ”€â”€ raw/                        # Dataset COMPAS brut
â”‚   â”œâ”€â”€ processed/                  # DonnÃ©es preprocessÃ©es
â”‚   â”œâ”€â”€ models/                     # ModÃ¨les entraÃ®nÃ©s sauvegardÃ©s
â”‚   â””â”€â”€ results/                    # RÃ©sultats analyses et visualisations
â”œâ”€â”€ Dashboard/                       # Dashboard interactif Streamlit
â”‚   â””â”€â”€ app.py                      # Application dashboard principal
â”œâ”€â”€ main_notebook.ipynb             # Notebook principal d'analyse
â”œâ”€â”€ requirements.txt                # DÃ©pendances Python
â”œâ”€â”€ install.sh                     # Script d'installation
â”œâ”€â”€ .gitignore                     # Fichiers ignorÃ©s par Git
â”œâ”€â”€ CLAUDE.md                      # Guide pour Claude Code
â””â”€â”€ README.md                      # Ce fichier
```

## ğŸ² Utilisation

### 1. Lancement du Notebook Principal

```bash
# Activer l'environnement virtuel
source venv/bin/activate

# Lancer Jupyter Lab
jupyter lab main_notebook.ipynb
```

### 2. Dashboard Interactif

```bash
# Lancer le dashboard Streamlit
streamlit run Dashboard/app.py
```

Le dashboard sera accessible Ã  l'adresse: http://localhost:8501

### 3. Scripts Python Individuels

```bash
# TÃ©lÃ©charger le dataset COMPAS
python src/data_acquisition.py

# Analyse exploratoire
python src/exploratory_analysis.py

# EntraÃ®nement des modÃ¨les
python src/model_training.py

# Analyse SHAP
python src/shap_analysis.py

# DÃ©tection des biais
python src/bias_analysis.py

# Mitigation des biais
python src/bias_mitigation.py

# Ã‰valuation de l'Ã©quitÃ©
python src/fairness_evaluation.py

# Comparaison d'interprÃ©tabilitÃ© (BONUS)
python src/interpretability_comparison.py
```

## ğŸ“Š DonnÃ©es et Analyse

### Dataset COMPAS

Le projet utilise le dataset COMPAS disponible sur Kaggle (`danofer/compass`) qui contient:

- **~10,000 enregistrements** de dÃ©fendeurs Ã©valuÃ©s par COMPAS
- **Variables dÃ©mographiques**: race, sexe, Ã¢ge
- **Historique criminel**: nombre d'antÃ©cÃ©dents, gravitÃ© des charges
- **Scores COMPAS**: Ã©valuation du risque de rÃ©cidive (1-10)
- **RÃ©cidive rÃ©elle**: rÃ©cidive observÃ©e dans les 2 ans

### MÃ©triques d'Ã‰quitÃ© AnalysÃ©es

- **ParitÃ© DÃ©mographique**: Ã‰galitÃ© des taux de prÃ©dictions positives
- **Ã‰galitÃ© des Chances**: Ã‰galitÃ© des taux de vrais positifs
- **Ã‰galitÃ© des Chances (FPR)**: Ã‰galitÃ© des taux de faux positifs  
- **Impact Disparate**: Respect de la rÃ¨gle des 80%
- **Calibration**: CohÃ©rence prÃ©dictions vs rÃ©alitÃ© par groupe

### Algorithmes ML ImplÃ©mentÃ©s

- **Logistic Regression** (baseline)
- **Random Forest**
- **XGBoost** (optimisÃ© Apple Silicon)
- **LightGBM** (optimisÃ© Mac M4 Pro)
- **Support Vector Machine**
- **Neural Network** (MLP simple)

## ğŸ” MÃ©thodes d'InterprÃ©tabilitÃ©

### SHAP (Principal)

- **TreeExplainer**: Pour modÃ¨les basÃ©s sur les arbres
- **KernelExplainer**: Pour modÃ¨les complexes
- **LinearExplainer**: Pour modÃ¨les linÃ©aires
- **Analyse des biais**: Comparaison valeurs SHAP par groupe dÃ©mographique

### LIME (Comparaison)

- **Explications locales**: Approximations linÃ©aires locales
- **FlexibilitÃ©**: Compatible avec tous types de modÃ¨les
- **StabilitÃ©**: Analyse de la consistance des explications

### SAGE (Bonus)

- **Interactions**: Prise en compte native des interactions entre features
- **Valeurs de Shapley**: ThÃ©orie des jeux appliquÃ©e
- **Performance**: Analyse des trade-offs computationnels

## ğŸ›¡ï¸ StratÃ©gies de Mitigation des Biais

### PrÃ©-traitement

- **Suppression de features sensibles**
- **RÃ©Ã©chantillonnage SMOTE Ã©quitable**
- **Augmentation de donnÃ©es consciente des biais**

### Traitement (In-processing)

- **EntraÃ®nement avec contraintes d'Ã©quitÃ©** (fairlearn)
- **Adversarial debiasing**
- **Multi-objectif optimization** (prÃ©cision + Ã©quitÃ©)

### Post-traitement

- **Calibration par groupe dÃ©mographique**
- **Optimisation des seuils de dÃ©cision**
- **Ajustement des scores de sortie**

## ğŸ“ˆ RÃ©sultats et Visualisations

### Dashboard Interactif

Le dashboard Streamlit propose 8 sections:

1. **ğŸ  Accueil**: Vue d'ensemble et mÃ©triques globales
2. **ğŸ“Š Analyse Exploratoire**: Distributions et dÃ©tection de biais
3. **ğŸ¤– ModÃ¨les et Performance**: Comparaison des algorithmes ML
4. **ğŸ” Analyse SHAP**: InterprÃ©tabilitÃ© et importance des features
5. **âš–ï¸ DÃ©tection des Biais**: MÃ©triques d'Ã©quitÃ© dÃ©taillÃ©es
6. **ğŸ›¡ï¸ Mitigation des Biais**: StratÃ©gies et trade-offs
7. **ğŸ“ˆ Ã‰valuation d'Ã‰quitÃ©**: EfficacitÃ© des mitigations
8. **ğŸ”„ Comparaison d'InterprÃ©tabilitÃ©**: SHAP vs LIME vs SAGE

### Rapports GÃ©nÃ©rÃ©s

- **Rapport d'analyse exploratoire** (HTML/PDF)
- **Rapport SHAP complet** avec visualisations
- **Rapport de dÃ©tection des biais** avec tests statistiques
- **Rapport d'Ã©valuation d'Ã©quitÃ©** avant/aprÃ¨s mitigation
- **Rapport de comparaison d'interprÃ©tabilitÃ©**

### Visualisations Principales

- **Summary plots SHAP** par groupe dÃ©mographique
- **Waterfall plots** pour explications individuelles
- **Dependence plots** montrant interactions features
- **Matrices de confusion** par groupe racial
- **Courbes ROC** comparatives par dÃ©mographie
- **Graphiques trade-off** performance vs Ã©quitÃ©

## ğŸ§ª Tests et Validation

### Tests Statistiques

- **Test ChiÂ² d'indÃ©pendance** entre race et prÃ©dictions
- **Test Mann-Whitney U** pour comparaisons de distributions
- **Tests de Kolmogorov-Smirnov** pour calibration
- **Intervalles de confiance** pour mÃ©triques d'Ã©quitÃ©

### Validation CroisÃ©e

- **Stratification** par cible ET attributs sensibles
- **Cross-validation temporelle** si applicable
- **Validation des performances post-mitigation**

## ğŸš¨ Limitations et ConsidÃ©rations Ã‰thiques

### Limitations Techniques

- **DonnÃ©es historiques**: Biais potentiels dans les donnÃ©es d'entraÃ®nement
- **Proxies indirects**: Variables corrÃ©lÃ©es avec race/sexe difficiles Ã  Ã©liminer
- **Trade-offs performance**: Mitigation peut rÃ©duire prÃ©cision prÃ©dictive
- **MÃ©triques d'Ã©quitÃ©**: ImpossibilitÃ© de satisfaire toutes simultanÃ©ment

### ConsidÃ©rations Ã‰thiques

- **Usage responsable**: ModÃ¨les pour analyse recherche uniquement
- **Transparence**: Documentation complÃ¨te des biais dÃ©tectÃ©s
- **Contexte juridique**: Implications dans le systÃ¨me judiciaire
- **Biais historiques**: Reproduction potentielle d'injustices passÃ©es

## ğŸ¤ Contribution et DÃ©veloppement

### Structure de DÃ©veloppement

```bash
# Tests des modules
python -m pytest tests/

# Linting du code
python -m flake8 src/

# VÃ©rification types
python -m mypy src/

# Formatage automatique
python -m black src/
```

### Ajout de Nouvelles Features

1. CrÃ©er une branche: `git checkout -b feature/nouvelle-feature`
2. DÃ©velopper dans `src/` avec tests appropriÃ©s
3. Mettre Ã  jour documentation et notebooks
4. CrÃ©er une pull request avec description dÃ©taillÃ©e

## ğŸ“š RÃ©fÃ©rences et Ressources

### Articles AcadÃ©miques

- **Lundberg & Lee (2017)**: "A Unified Approach to Interpreting Model Predictions" (SHAP)
- **Ribeiro et al. (2016)**: "Why Should I Trust You?" (LIME)
- **Doshi-Velez & Kim (2017)**: "Towards A Rigorous Science of Interpretable Machine Learning"

### Datasets et Outils

- **ProPublica COMPAS Analysis**: Investigation originale sur les biais COMPAS
- **Fairlearn**: BibliothÃ¨que Microsoft pour Ã©quitÃ© algorithmique
- **AI Fairness 360**: Toolkit IBM pour dÃ©tection et mitigation des biais

### Documentation Technique

- **SHAP Documentation**: https://shap.readthedocs.io/
- **LIME Documentation**: https://github.com/marcotcr/lime
- **Fairlearn Guide**: https://fairlearn.org/

## ğŸ“ Support et Contact

### Issues et Bugs

Signaler les problÃ¨mes via les GitHub Issues avec:
- Description dÃ©taillÃ©e du problÃ¨me
- Ã‰tapes pour reproduire
- Logs d'erreur si disponibles
- Configuration systÃ¨me

### Questions et Discussions

Utiliser les GitHub Discussions pour:
- Questions sur l'interprÃ©tation des rÃ©sultats
- Suggestions d'amÃ©liorations
- Discussions sur les aspects Ã©thiques
- Partage d'analyses complÃ©mentaires

## ğŸ“„ Licence et Citation

### Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour les dÃ©tails complets.

### Citation

Si vous utilisez ce projet dans vos recherches, veuillez citer:

```bibtex
@software{sesame_shap_2025,
  title={SESAME-SHAP: COMPAS Bias Analysis with SHAP Interpretability},
  author={Projet SESAME-SHAP},
  year={2025},
  url={https://github.com/votre-repo/sesame-shap}
}
```

---

**âš–ï¸ "SÃ©same, ouvre-toi" - DÃ©verrouillant les secrets des modÃ¨les complexes pour rÃ©vÃ©ler leur vÃ©ritable potentiel Ã©quitable.**

*DÃ©veloppÃ© avec â¤ï¸ pour la recherche en IA Ã©thique et interprÃ©table*